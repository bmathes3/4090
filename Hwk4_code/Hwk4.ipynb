{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hwk1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x186bb5bd430>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "data_path ='C:/Users/Brad/Documents/4090/dlwpt-code-master/dlwpt-code-master/data-unversioned/p1ch7/'\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path, train=False, download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {6: 0, 7: 1, 8: 2, 9: 3 }\n",
    "class_names = ['frog', 'horse', 'ship', 'truck']\n",
    "cifar2 = [(img, label_map[label])\n",
    "          for img, label in cifar10 \n",
    "          if label in [6, 9]]\n",
    "cifar2_val = [(img, label_map[label])\n",
    "              for img, label in cifar10_val\n",
    "              if label in [6, 9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0900, 0.2447, 0.6652])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0900, 0.2447, 0.6652],\n",
       "        [0.0900, 0.2447, 0.6652]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "x = torch.tensor([[1.0, 2.0, 3.0],\n",
    "                  [1.0, 2.0, 3.0]])\n",
    "\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 4),\n",
    "            nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, _ = cifar2[0]\n",
    "\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch = img.view(-1).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2573, 0.2700, 0.2368, 0.2360]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(img_batch)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, index = torch.max(out, dim=1)\n",
    "\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.tensor([\n",
    "    [0.6, 0.4],\n",
    "    [0.9, 0.1],\n",
    "    [0.3, 0.7],\n",
    "    [0.2, 0.8],\n",
    "])\n",
    "class_index = torch.tensor([0, 0, 1, 1]).unsqueeze(1)\n",
    "\n",
    "truth = torch.zeros((4,2))\n",
    "truth.scatter_(dim=1, index=class_index, value=1.0)\n",
    "truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1500)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mse(out):\n",
    "    return ((out - truth) ** 2).sum(dim=1).mean()\n",
    "mse(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6000],\n",
       "        [0.9000],\n",
       "        [0.7000],\n",
       "        [0.8000]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.gather(dim=1, index=class_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3024])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def likelihood(out):\n",
    "    prod = 1.0\n",
    "    for x in out.gather(dim=1, index=class_index):\n",
    "        prod *= x\n",
    "    return prod\n",
    "\n",
    "likelihood(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1960])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def neg_log_likelihood(out):\n",
    "    return -likelihood(out).log()\n",
    "\n",
    "neg_log_likelihood(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0750, 0.1500, 0.2500, 0.4750])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out0 = out.clone().detach()\n",
    "out0[0] = torch.tensor([0.9, 0.1]) # more right\n",
    "\n",
    "out2 = out.clone().detach()\n",
    "out2[0] = torch.tensor([0.4, 0.6]) # slightly wrong\n",
    "\n",
    "out3 = out.clone().detach()\n",
    "out3[0] = torch.tensor([0.1, 0.9]) # very wrong\n",
    "\n",
    "mse_comparison = torch.tensor([mse(o) for o in [out0, out, out2, out3]])\n",
    "mse_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-50.0000,   0.0000,  66.6667, 216.6667])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((mse_comparison / mse_comparison[1]) - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7905, 1.1960, 1.6015, 2.9878])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll_comparison = torch.tensor([neg_log_likelihood(o) \n",
    "                               for o in [out0, out, out2, out3]])\n",
    "nll_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-33.9016,   0.0000,  33.9016, 149.8121])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((nll_comparison / nll_comparison[1]) - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "x = torch.tensor([[0.0, 104.0]])\n",
    "\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "x = torch.tensor([[0.0, 104.0]])\n",
    "\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-inf, 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(softmax(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-104.,    0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(log_softmax(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0928, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = cifar2[0]\n",
    "\n",
    "out = model(img.view(-1).unsqueeze(0))\n",
    "\n",
    "loss(out, torch.tensor([label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.000621\n",
      "Epoch: 1, Loss: 0.000146\n",
      "Epoch: 2, Loss: 0.000003\n",
      "Epoch: 3, Loss: 0.000011\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-1af1066f5253>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 4),\n",
    "            nn.LogSoftmax(dim=1))\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "n_epochs = 200\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for img, label in cifar2:\n",
    "        out = model(img.view(-1).unsqueeze(0))\n",
    "        loss = loss_fn(out, torch.tensor([label]))\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.700020\n",
      "Epoch: 1, Loss: 0.539794\n",
      "Epoch: 2, Loss: 0.184901\n",
      "Epoch: 3, Loss: 0.521425\n",
      "Epoch: 4, Loss: 0.166598\n",
      "Epoch: 5, Loss: 0.402926\n",
      "Epoch: 6, Loss: 0.369970\n",
      "Epoch: 7, Loss: 0.138595\n",
      "Epoch: 8, Loss: 0.379537\n",
      "Epoch: 9, Loss: 0.313042\n",
      "Epoch: 10, Loss: 0.073657\n",
      "Epoch: 11, Loss: 0.080797\n",
      "Epoch: 12, Loss: 0.156792\n",
      "Epoch: 13, Loss: 0.170587\n",
      "Epoch: 14, Loss: 0.173987\n",
      "Epoch: 15, Loss: 0.116315\n",
      "Epoch: 16, Loss: 0.160142\n",
      "Epoch: 17, Loss: 0.130185\n",
      "Epoch: 18, Loss: 0.107380\n",
      "Epoch: 19, Loss: 0.274028\n",
      "Epoch: 20, Loss: 0.095587\n",
      "Epoch: 21, Loss: 0.283462\n",
      "Epoch: 22, Loss: 0.092773\n",
      "Epoch: 23, Loss: 0.085648\n",
      "Epoch: 24, Loss: 0.134724\n",
      "Epoch: 25, Loss: 0.162577\n",
      "Epoch: 26, Loss: 0.125842\n",
      "Epoch: 27, Loss: 0.090967\n",
      "Epoch: 28, Loss: 0.134966\n",
      "Epoch: 29, Loss: 0.082506\n",
      "Epoch: 30, Loss: 0.193432\n",
      "Epoch: 31, Loss: 0.053735\n",
      "Epoch: 32, Loss: 0.058271\n",
      "Epoch: 33, Loss: 0.105742\n",
      "Epoch: 34, Loss: 0.026639\n",
      "Epoch: 35, Loss: 0.062957\n",
      "Epoch: 36, Loss: 0.028816\n",
      "Epoch: 37, Loss: 0.075163\n",
      "Epoch: 38, Loss: 0.036199\n",
      "Epoch: 39, Loss: 0.063562\n",
      "Epoch: 40, Loss: 0.026357\n",
      "Epoch: 41, Loss: 0.038799\n",
      "Epoch: 42, Loss: 0.049338\n",
      "Epoch: 43, Loss: 0.026940\n",
      "Epoch: 44, Loss: 0.057755\n",
      "Epoch: 45, Loss: 0.072468\n",
      "Epoch: 46, Loss: 0.037524\n",
      "Epoch: 47, Loss: 0.039176\n",
      "Epoch: 48, Loss: 0.037581\n",
      "Epoch: 49, Loss: 0.035148\n",
      "Epoch: 50, Loss: 0.022356\n",
      "Epoch: 51, Loss: 0.034273\n",
      "Epoch: 52, Loss: 0.010406\n",
      "Epoch: 53, Loss: 0.017895\n",
      "Epoch: 54, Loss: 0.014676\n",
      "Epoch: 55, Loss: 0.025565\n",
      "Epoch: 56, Loss: 0.002120\n",
      "Epoch: 57, Loss: 0.020923\n",
      "Epoch: 58, Loss: 0.010581\n",
      "Epoch: 59, Loss: 0.031121\n",
      "Epoch: 60, Loss: 0.006419\n",
      "Epoch: 61, Loss: 0.023160\n",
      "Epoch: 62, Loss: 0.024132\n",
      "Epoch: 63, Loss: 0.007451\n",
      "Epoch: 64, Loss: 0.021984\n",
      "Epoch: 65, Loss: 0.028478\n",
      "Epoch: 66, Loss: 0.011856\n",
      "Epoch: 67, Loss: 0.010457\n",
      "Epoch: 68, Loss: 0.005781\n",
      "Epoch: 69, Loss: 0.005049\n",
      "Epoch: 70, Loss: 0.026934\n",
      "Epoch: 71, Loss: 0.002311\n",
      "Epoch: 72, Loss: 0.015398\n",
      "Epoch: 73, Loss: 0.018578\n",
      "Epoch: 74, Loss: 0.007411\n",
      "Epoch: 75, Loss: 0.022813\n",
      "Epoch: 76, Loss: 0.011037\n",
      "Epoch: 77, Loss: 0.008684\n",
      "Epoch: 78, Loss: 0.004888\n",
      "Epoch: 79, Loss: 0.018731\n",
      "Epoch: 80, Loss: 0.009502\n",
      "Epoch: 81, Loss: 0.017849\n",
      "Epoch: 82, Loss: 0.007736\n",
      "Epoch: 83, Loss: 0.012083\n",
      "Epoch: 84, Loss: 0.012047\n",
      "Epoch: 85, Loss: 0.003417\n",
      "Epoch: 86, Loss: 0.004631\n",
      "Epoch: 87, Loss: 0.012552\n",
      "Epoch: 88, Loss: 0.008421\n",
      "Epoch: 89, Loss: 0.004820\n",
      "Epoch: 90, Loss: 0.011987\n",
      "Epoch: 91, Loss: 0.010163\n",
      "Epoch: 92, Loss: 0.010824\n",
      "Epoch: 93, Loss: 0.007553\n",
      "Epoch: 94, Loss: 0.005346\n",
      "Epoch: 95, Loss: 0.003741\n",
      "Epoch: 96, Loss: 0.006175\n",
      "Epoch: 97, Loss: 0.008824\n",
      "Epoch: 98, Loss: 0.013519\n",
      "Epoch: 99, Loss: 0.009787\n",
      "Epoch: 100, Loss: 0.006429\n",
      "Epoch: 101, Loss: 0.008855\n",
      "Epoch: 102, Loss: 0.014443\n",
      "Epoch: 103, Loss: 0.011035\n",
      "Epoch: 104, Loss: 0.008353\n",
      "Epoch: 105, Loss: 0.006363\n",
      "Epoch: 106, Loss: 0.008527\n",
      "Epoch: 107, Loss: 0.004510\n",
      "Epoch: 108, Loss: 0.003296\n",
      "Epoch: 109, Loss: 0.007336\n",
      "Epoch: 110, Loss: 0.008760\n",
      "Epoch: 111, Loss: 0.005112\n",
      "Epoch: 112, Loss: 0.004670\n",
      "Epoch: 113, Loss: 0.014805\n",
      "Epoch: 114, Loss: 0.004255\n",
      "Epoch: 115, Loss: 0.005252\n",
      "Epoch: 116, Loss: 0.006565\n",
      "Epoch: 117, Loss: 0.010606\n",
      "Epoch: 118, Loss: 0.005743\n",
      "Epoch: 119, Loss: 0.014146\n",
      "Epoch: 120, Loss: 0.006122\n",
      "Epoch: 121, Loss: 0.002516\n",
      "Epoch: 122, Loss: 0.006124\n",
      "Epoch: 123, Loss: 0.010590\n",
      "Epoch: 124, Loss: 0.005916\n",
      "Epoch: 125, Loss: 0.004995\n",
      "Epoch: 126, Loss: 0.003416\n",
      "Epoch: 127, Loss: 0.005164\n",
      "Epoch: 128, Loss: 0.004412\n",
      "Epoch: 129, Loss: 0.001986\n",
      "Epoch: 130, Loss: 0.002411\n",
      "Epoch: 131, Loss: 0.003917\n",
      "Epoch: 132, Loss: 0.001859\n",
      "Epoch: 133, Loss: 0.002271\n",
      "Epoch: 134, Loss: 0.002966\n",
      "Epoch: 135, Loss: 0.003730\n",
      "Epoch: 136, Loss: 0.003172\n",
      "Epoch: 137, Loss: 0.004770\n",
      "Epoch: 138, Loss: 0.005049\n",
      "Epoch: 139, Loss: 0.004395\n",
      "Epoch: 140, Loss: 0.001881\n",
      "Epoch: 141, Loss: 0.003019\n",
      "Epoch: 142, Loss: 0.006928\n",
      "Epoch: 143, Loss: 0.001451\n",
      "Epoch: 144, Loss: 0.003474\n",
      "Epoch: 145, Loss: 0.005529\n",
      "Epoch: 146, Loss: 0.005262\n",
      "Epoch: 147, Loss: 0.007110\n",
      "Epoch: 148, Loss: 0.004664\n",
      "Epoch: 149, Loss: 0.005066\n",
      "Epoch: 150, Loss: 0.009239\n",
      "Epoch: 151, Loss: 0.004189\n",
      "Epoch: 152, Loss: 0.002901\n",
      "Epoch: 153, Loss: 0.002720\n",
      "Epoch: 154, Loss: 0.004095\n",
      "Epoch: 155, Loss: 0.001857\n",
      "Epoch: 156, Loss: 0.003408\n",
      "Epoch: 157, Loss: 0.003366\n",
      "Epoch: 158, Loss: 0.003136\n",
      "Epoch: 159, Loss: 0.001321\n",
      "Epoch: 160, Loss: 0.003768\n",
      "Epoch: 161, Loss: 0.005493\n",
      "Epoch: 162, Loss: 0.002924\n",
      "Epoch: 163, Loss: 0.001743\n",
      "Epoch: 164, Loss: 0.004090\n",
      "Epoch: 165, Loss: 0.001427\n",
      "Epoch: 166, Loss: 0.005159\n",
      "Epoch: 167, Loss: 0.003674\n",
      "Epoch: 168, Loss: 0.001326\n",
      "Epoch: 169, Loss: 0.002698\n",
      "Epoch: 170, Loss: 0.003496\n",
      "Epoch: 171, Loss: 0.002599\n",
      "Epoch: 172, Loss: 0.004927\n",
      "Epoch: 173, Loss: 0.001266\n",
      "Epoch: 174, Loss: 0.001823\n",
      "Epoch: 175, Loss: 0.002750\n",
      "Epoch: 176, Loss: 0.002809\n",
      "Epoch: 177, Loss: 0.005221\n",
      "Epoch: 178, Loss: 0.001598\n",
      "Epoch: 179, Loss: 0.001996\n",
      "Epoch: 180, Loss: 0.001937\n",
      "Epoch: 181, Loss: 0.005859\n",
      "Epoch: 182, Loss: 0.004175\n",
      "Epoch: 183, Loss: 0.001661\n",
      "Epoch: 184, Loss: 0.002691\n",
      "Epoch: 185, Loss: 0.003137\n",
      "Epoch: 186, Loss: 0.001277\n",
      "Epoch: 187, Loss: 0.002087\n",
      "Epoch: 188, Loss: 0.006063\n",
      "Epoch: 189, Loss: 0.002318\n",
      "Epoch: 190, Loss: 0.008482\n",
      "Epoch: 191, Loss: 0.001328\n",
      "Epoch: 192, Loss: 0.003977\n",
      "Epoch: 193, Loss: 0.001617\n",
      "Epoch: 194, Loss: 0.003693\n",
      "Epoch: 195, Loss: 0.002974\n",
      "Epoch: 196, Loss: 0.000947\n",
      "Epoch: 197, Loss: 0.000957\n",
      "Epoch: 198, Loss: 0.001655\n",
      "Epoch: 199, Loss: 0.004067\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 4),\n",
    "            nn.LogSoftmax(dim=1))\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "n_epochs = 200\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.913000\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hwk1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 1024),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 2),\n",
    "            nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 1024),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 2))\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.607313\n",
      "Epoch: 1, Loss: 0.332005\n",
      "Epoch: 2, Loss: 0.343704\n",
      "Epoch: 3, Loss: 0.285983\n",
      "Epoch: 4, Loss: 0.159504\n",
      "Epoch: 5, Loss: 0.317812\n",
      "Epoch: 6, Loss: 0.076195\n",
      "Epoch: 7, Loss: 0.084640\n",
      "Epoch: 8, Loss: 0.621011\n",
      "Epoch: 9, Loss: 0.221187\n",
      "Epoch: 10, Loss: 0.111456\n",
      "Epoch: 11, Loss: 0.251891\n",
      "Epoch: 12, Loss: 0.274677\n",
      "Epoch: 13, Loss: 0.264373\n",
      "Epoch: 14, Loss: 0.363818\n",
      "Epoch: 15, Loss: 0.336531\n",
      "Epoch: 16, Loss: 0.676009\n",
      "Epoch: 17, Loss: 0.060131\n",
      "Epoch: 18, Loss: 0.125624\n",
      "Epoch: 19, Loss: 0.250098\n",
      "Epoch: 20, Loss: 0.042196\n",
      "Epoch: 21, Loss: 0.022132\n",
      "Epoch: 22, Loss: 0.238810\n",
      "Epoch: 23, Loss: 0.084742\n",
      "Epoch: 24, Loss: 0.063083\n",
      "Epoch: 25, Loss: 0.114829\n",
      "Epoch: 26, Loss: 0.059178\n",
      "Epoch: 27, Loss: 0.014512\n",
      "Epoch: 28, Loss: 0.007952\n",
      "Epoch: 29, Loss: 0.011046\n",
      "Epoch: 30, Loss: 0.027810\n",
      "Epoch: 31, Loss: 0.043188\n",
      "Epoch: 32, Loss: 0.005255\n",
      "Epoch: 33, Loss: 0.004669\n",
      "Epoch: 34, Loss: 0.271344\n",
      "Epoch: 35, Loss: 0.003364\n",
      "Epoch: 36, Loss: 0.003607\n",
      "Epoch: 37, Loss: 0.009931\n",
      "Epoch: 38, Loss: 0.002465\n",
      "Epoch: 39, Loss: 0.007284\n",
      "Epoch: 40, Loss: 0.004489\n",
      "Epoch: 41, Loss: 0.007471\n",
      "Epoch: 42, Loss: 0.001599\n",
      "Epoch: 43, Loss: 0.003599\n",
      "Epoch: 44, Loss: 0.004412\n",
      "Epoch: 45, Loss: 0.002193\n",
      "Epoch: 46, Loss: 0.003112\n",
      "Epoch: 47, Loss: 0.001287\n",
      "Epoch: 48, Loss: 0.001361\n",
      "Epoch: 49, Loss: 0.001916\n",
      "Epoch: 50, Loss: 0.001926\n",
      "Epoch: 51, Loss: 0.003243\n",
      "Epoch: 52, Loss: 0.002378\n",
      "Epoch: 53, Loss: 0.000674\n",
      "Epoch: 54, Loss: 0.001671\n",
      "Epoch: 55, Loss: 0.000804\n",
      "Epoch: 56, Loss: 0.001025\n",
      "Epoch: 57, Loss: 0.002360\n",
      "Epoch: 58, Loss: 0.000437\n",
      "Epoch: 59, Loss: 0.000319\n",
      "Epoch: 60, Loss: 0.000262\n",
      "Epoch: 61, Loss: 0.001770\n",
      "Epoch: 62, Loss: 0.000932\n",
      "Epoch: 63, Loss: 0.000609\n",
      "Epoch: 64, Loss: 0.001765\n",
      "Epoch: 65, Loss: 0.000777\n",
      "Epoch: 66, Loss: 0.001569\n",
      "Epoch: 67, Loss: 0.002012\n",
      "Epoch: 68, Loss: 0.000456\n",
      "Epoch: 69, Loss: 0.000983\n",
      "Epoch: 70, Loss: 0.000420\n",
      "Epoch: 71, Loss: 0.000451\n",
      "Epoch: 72, Loss: 0.000414\n",
      "Epoch: 73, Loss: 0.000313\n",
      "Epoch: 74, Loss: 0.000448\n",
      "Epoch: 75, Loss: 0.000448\n",
      "Epoch: 76, Loss: 0.000967\n",
      "Epoch: 77, Loss: 0.000083\n",
      "Epoch: 78, Loss: 0.000311\n",
      "Epoch: 79, Loss: 0.001002\n",
      "Epoch: 80, Loss: 0.001045\n",
      "Epoch: 81, Loss: 0.000288\n",
      "Epoch: 82, Loss: 0.000611\n",
      "Epoch: 83, Loss: 0.000208\n",
      "Epoch: 84, Loss: 0.000266\n",
      "Epoch: 85, Loss: 0.000552\n",
      "Epoch: 86, Loss: 0.001114\n",
      "Epoch: 87, Loss: 0.000626\n",
      "Epoch: 88, Loss: 0.000392\n",
      "Epoch: 89, Loss: 0.000324\n",
      "Epoch: 90, Loss: 0.000361\n",
      "Epoch: 91, Loss: 0.000133\n",
      "Epoch: 92, Loss: 0.000346\n",
      "Epoch: 93, Loss: 0.000405\n",
      "Epoch: 94, Loss: 0.000883\n",
      "Epoch: 95, Loss: 0.000574\n",
      "Epoch: 96, Loss: 0.000495\n",
      "Epoch: 97, Loss: 0.000697\n",
      "Epoch: 98, Loss: 0.000835\n",
      "Epoch: 99, Loss: 0.000149\n",
      "Epoch: 100, Loss: 0.000190\n",
      "Epoch: 101, Loss: 0.000437\n",
      "Epoch: 102, Loss: 0.000211\n",
      "Epoch: 103, Loss: 0.000151\n",
      "Epoch: 104, Loss: 0.000347\n",
      "Epoch: 105, Loss: 0.000418\n",
      "Epoch: 106, Loss: 0.000464\n",
      "Epoch: 107, Loss: 0.000315\n",
      "Epoch: 108, Loss: 0.000219\n",
      "Epoch: 109, Loss: 0.000315\n",
      "Epoch: 110, Loss: 0.000862\n",
      "Epoch: 111, Loss: 0.000176\n",
      "Epoch: 112, Loss: 0.000101\n",
      "Epoch: 113, Loss: 0.000153\n",
      "Epoch: 114, Loss: 0.000048\n",
      "Epoch: 115, Loss: 0.000105\n",
      "Epoch: 116, Loss: 0.000338\n",
      "Epoch: 117, Loss: 0.000514\n",
      "Epoch: 118, Loss: 0.000144\n",
      "Epoch: 119, Loss: 0.000100\n",
      "Epoch: 120, Loss: 0.000080\n",
      "Epoch: 121, Loss: 0.000287\n",
      "Epoch: 122, Loss: 0.000323\n",
      "Epoch: 123, Loss: 0.000253\n",
      "Epoch: 124, Loss: 0.000132\n",
      "Epoch: 125, Loss: 0.000166\n",
      "Epoch: 126, Loss: 0.000338\n",
      "Epoch: 127, Loss: 0.000164\n",
      "Epoch: 128, Loss: 0.000704\n",
      "Epoch: 129, Loss: 0.000306\n",
      "Epoch: 130, Loss: 0.000402\n",
      "Epoch: 131, Loss: 0.000514\n",
      "Epoch: 132, Loss: 0.000085\n",
      "Epoch: 133, Loss: 0.000243\n",
      "Epoch: 134, Loss: 0.000144\n",
      "Epoch: 135, Loss: 0.000302\n",
      "Epoch: 136, Loss: 0.000366\n",
      "Epoch: 137, Loss: 0.000385\n",
      "Epoch: 138, Loss: 0.000465\n",
      "Epoch: 139, Loss: 0.000153\n",
      "Epoch: 140, Loss: 0.000141\n",
      "Epoch: 141, Loss: 0.000192\n",
      "Epoch: 142, Loss: 0.000290\n",
      "Epoch: 143, Loss: 0.000100\n",
      "Epoch: 144, Loss: 0.000200\n",
      "Epoch: 145, Loss: 0.000323\n",
      "Epoch: 146, Loss: 0.000182\n",
      "Epoch: 147, Loss: 0.000357\n",
      "Epoch: 148, Loss: 0.000077\n",
      "Epoch: 149, Loss: 0.000367\n",
      "Epoch: 150, Loss: 0.000276\n",
      "Epoch: 151, Loss: 0.000088\n",
      "Epoch: 152, Loss: 0.000435\n",
      "Epoch: 153, Loss: 0.000145\n",
      "Epoch: 154, Loss: 0.000547\n",
      "Epoch: 155, Loss: 0.000095\n",
      "Epoch: 156, Loss: 0.000222\n",
      "Epoch: 157, Loss: 0.000230\n",
      "Epoch: 158, Loss: 0.000070\n",
      "Epoch: 159, Loss: 0.000078\n",
      "Epoch: 160, Loss: 0.000103\n",
      "Epoch: 161, Loss: 0.000440\n",
      "Epoch: 162, Loss: 0.000352\n",
      "Epoch: 163, Loss: 0.000181\n",
      "Epoch: 164, Loss: 0.000287\n",
      "Epoch: 165, Loss: 0.000382\n",
      "Epoch: 166, Loss: 0.000325\n",
      "Epoch: 167, Loss: 0.000235\n",
      "Epoch: 168, Loss: 0.000347\n",
      "Epoch: 169, Loss: 0.000569\n",
      "Epoch: 170, Loss: 0.000130\n",
      "Epoch: 171, Loss: 0.000079\n",
      "Epoch: 172, Loss: 0.000130\n",
      "Epoch: 173, Loss: 0.000129\n",
      "Epoch: 174, Loss: 0.000063\n",
      "Epoch: 175, Loss: 0.000180\n",
      "Epoch: 176, Loss: 0.000160\n",
      "Epoch: 177, Loss: 0.000202\n",
      "Epoch: 178, Loss: 0.000171\n",
      "Epoch: 179, Loss: 0.000249\n",
      "Epoch: 180, Loss: 0.000511\n",
      "Epoch: 181, Loss: 0.000036\n",
      "Epoch: 182, Loss: 0.000195\n",
      "Epoch: 183, Loss: 0.000145\n",
      "Epoch: 184, Loss: 0.000016\n",
      "Epoch: 185, Loss: 0.000377\n",
      "Epoch: 186, Loss: 0.000029\n",
      "Epoch: 187, Loss: 0.000244\n",
      "Epoch: 188, Loss: 0.000265\n",
      "Epoch: 189, Loss: 0.000104\n",
      "Epoch: 190, Loss: 0.000164\n",
      "Epoch: 191, Loss: 0.000188\n",
      "Epoch: 192, Loss: 0.000162\n",
      "Epoch: 193, Loss: 0.000096\n",
      "Epoch: 194, Loss: 0.000134\n",
      "Epoch: 195, Loss: 0.000084\n",
      "Epoch: 196, Loss: 0.000115\n",
      "Epoch: 197, Loss: 0.000066\n",
      "Epoch: 198, Loss: 0.000051\n",
      "Epoch: 199, Loss: 0.000170\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 1024),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 4))\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 200\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.905000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([p.numel() for p in model.parameters() if p.requires_grad == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model = nn.Sequential(\n",
    "                nn.Linear(3072, 512),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(512, 2),\n",
    "                nn.LogSoftmax(dim=1))\n",
    "\n",
    "sum([p.numel() for p in first_model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([p.numel() for p in nn.Linear(3072, 512).parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([p.numel() for p in nn.Linear(3072, 1024).parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(3072, 1024)\n",
    "\n",
    "linear.weight.shape, linear.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(3, 16, kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, _ = cifar2[0]\n",
    "\n",
    "output = conv(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.unsqueeze(0).shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img.permute(1, 2, 0), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = conv(img.unsqueeze(0))\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    conv.bias.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    conv.weight.fill_(1.0 / 9.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = conv(img.unsqueeze(0))\n",
    "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    conv.weight[:] = torch.tensor([[-1.0, 0.0, 1.0],\n",
    "                                   [-1.0, 0.0, 1.0],\n",
    "                                   [-1.0, 0.0, 1.0]])\n",
    "    conv.bias.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = conv(img.unsqueeze(0))\n",
    "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hwk4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = nn.MaxPool2d(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 16, 16])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pool(img.unsqueeze(0))\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2),\n",
    "            # WARNING: something missing here\n",
    "            nn.Linear(512, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18156"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x8 and 512x32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-9c784fd7714c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1692\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1693\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x8 and 512x32)"
     ]
    }
   ],
   "source": [
    "model(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.act4 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = self.act4(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18090"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "\n",
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hwk4-2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0769,  0.0367, -0.1418, -0.0365]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "model = Net()\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime  # <1>\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):  # <2>\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:  # <3>\n",
    "            \n",
    "            outputs = model(imgs)  # <4>\n",
    "            \n",
    "            loss = loss_fn(outputs, labels)  # <5>\n",
    "\n",
    "            optimizer.zero_grad()  # <6>\n",
    "            \n",
    "            loss.backward()  # <7>\n",
    "            \n",
    "            optimizer.step()  # <8>\n",
    "\n",
    "            loss_train += loss.item()  # <9>\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))  # <10>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-21 18:24:09.890126 Epoch 1, Training loss 0.6444759665021471\n",
      "2021-04-21 18:24:31.482989 Epoch 10, Training loss 0.17408925840619263\n",
      "2021-04-21 18:24:56.483869 Epoch 20, Training loss 0.10203702878325609\n",
      "2021-04-21 18:25:22.954892 Epoch 30, Training loss 0.0735774517806757\n",
      "2021-04-21 18:25:48.313882 Epoch 40, Training loss 0.057291600423135386\n",
      "2021-04-21 18:26:14.946601 Epoch 50, Training loss 0.047367630655444255\n",
      "2021-04-21 18:26:40.926584 Epoch 60, Training loss 0.03975336703584547\n",
      "2021-04-21 18:27:07.638663 Epoch 70, Training loss 0.03403935049791008\n",
      "2021-04-21 18:27:34.929574 Epoch 80, Training loss 0.028880257138709543\n",
      "2021-04-21 18:28:01.583125 Epoch 90, Training loss 0.024637013178461106\n",
      "2021-04-21 18:28:29.581828 Epoch 100, Training loss 0.019156839928417733\n",
      "2021-04-21 18:28:55.958610 Epoch 110, Training loss 0.01684642701475009\n",
      "2021-04-21 18:29:22.337377 Epoch 120, Training loss 0.01298315448991978\n",
      "2021-04-21 18:29:50.195217 Epoch 130, Training loss 0.010160728137877882\n",
      "2021-04-21 18:30:17.773808 Epoch 140, Training loss 0.008431413679555723\n",
      "2021-04-21 18:30:44.174894 Epoch 150, Training loss 0.007353336143027101\n",
      "2021-04-21 18:31:10.865646 Epoch 160, Training loss 0.006196092833462875\n",
      "2021-04-21 18:31:37.001868 Epoch 170, Training loss 0.0051683519924634914\n",
      "2021-04-21 18:32:02.422363 Epoch 180, Training loss 0.004330789991984886\n",
      "2021-04-21 18:32:27.760026 Epoch 190, Training loss 0.003765484816076829\n",
      "2021-04-21 18:32:54.346121 Epoch 200, Training loss 0.0033268144504006976\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=True)  # <1>\n",
    "\n",
    "model = Net()  #  <2>\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)  #  <3>\n",
    "loss_fn = nn.CrossEntropyLoss()  #  <4>\n",
    "\n",
    "training_loop(  # <5>\n",
    "    n_epochs = 200,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 1.00\n",
      "Accuracy val: 0.98\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():  # <1>\n",
    "            for imgs, labels in loader:\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
    "                total += labels.shape[0]  # <3>\n",
    "                correct += int((predicted == labels).sum())  # <4>\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "        \n",
    "validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Hwk2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1051,  0.0927,  0.0289, -0.0531,  0.0245,  0.0713,  0.1372,  0.0733,\n",
       "         -0.0660, -0.1187]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "model = Net()\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime  # <1>\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):  # <2>\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:  # <3>\n",
    "            \n",
    "            outputs = model(imgs)  # <4>\n",
    "            \n",
    "            loss = loss_fn(outputs, labels)  # <5>\n",
    "\n",
    "            optimizer.zero_grad()  # <6>\n",
    "            \n",
    "            loss.backward()  # <7>\n",
    "            \n",
    "            optimizer.step()  # <8>\n",
    "\n",
    "            loss_train += loss.item()  # <9>\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))  # <10>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-21 18:46:05.152122 Epoch 1, Training loss 2.029663713844231\n",
      "2021-04-21 18:49:12.914402 Epoch 10, Training loss 1.153426479500578\n",
      "2021-04-21 18:52:43.158874 Epoch 20, Training loss 0.97370917420558\n",
      "2021-04-21 18:56:12.543778 Epoch 30, Training loss 0.8852849273425539\n",
      "2021-04-21 18:59:42.165758 Epoch 40, Training loss 0.8273465525158836\n",
      "2021-04-21 19:03:18.269952 Epoch 50, Training loss 0.7887913025248691\n",
      "2021-04-21 19:06:48.375026 Epoch 60, Training loss 0.7538359201777621\n",
      "2021-04-21 19:10:20.735413 Epoch 70, Training loss 0.7272006276699589\n",
      "2021-04-21 19:13:51.034919 Epoch 80, Training loss 0.7039669872549794\n",
      "2021-04-21 19:17:21.923673 Epoch 90, Training loss 0.6821176612087528\n",
      "2021-04-21 19:20:52.113565 Epoch 100, Training loss 0.6606125457741111\n",
      "2021-04-21 19:24:22.912471 Epoch 110, Training loss 0.6448947941631917\n",
      "2021-04-21 19:27:54.105152 Epoch 120, Training loss 0.6309462723219791\n",
      "2021-04-21 19:31:26.071002 Epoch 130, Training loss 0.6184532960967335\n",
      "2021-04-21 19:34:58.073611 Epoch 140, Training loss 0.6044420016848523\n",
      "2021-04-21 19:38:28.837241 Epoch 150, Training loss 0.5995403805276012\n",
      "2021-04-21 19:42:03.953881 Epoch 160, Training loss 0.5908436305687556\n",
      "2021-04-21 19:45:36.070481 Epoch 170, Training loss 0.5809471969638029\n",
      "2021-04-21 19:49:11.563937 Epoch 180, Training loss 0.5706390660742054\n",
      "2021-04-21 19:52:47.431374 Epoch 190, Training loss 0.565698104898643\n",
      "2021-04-21 19:56:26.194277 Epoch 200, Training loss 0.5639397336546418\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
    "                                           shuffle=True)  # <1>\n",
    "\n",
    "model = Net()  #  <2>\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)  #  <3>\n",
    "loss_fn = nn.CrossEntropyLoss()  #  <4>\n",
    "\n",
    "training_loop(  # <5>\n",
    "    n_epochs = 200,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.80\n",
      "Accuracy val: 0.61\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():  # <1>\n",
    "            for imgs, labels in loader:\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
    "                total += labels.shape[0]  # <3>\n",
    "                correct += int((predicted == labels).sum())  # <4>\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "        \n",
    "validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hwk2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(8, 4, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * 4, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv3(out)), 2)\n",
    "        out = out.view(-1, 4 * 4 * 4)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0643, -0.1141,  0.0634,  0.0546,  0.1250,  0.1496, -0.1668, -0.1009,\n",
       "          0.0061, -0.1099]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(8, 4, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * 4, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv3(out)), 2)\n",
    "        out = out.view(-1, 4 * 4 * 4)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "model = Net()\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime  # <1>\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):  # <2>\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:  # <3>\n",
    "            \n",
    "            outputs = model(imgs)  # <4>\n",
    "            \n",
    "            loss = loss_fn(outputs, labels)  # <5>\n",
    "\n",
    "            optimizer.zero_grad()  # <6>\n",
    "            \n",
    "            loss.backward()  # <7>\n",
    "            \n",
    "            optimizer.step()  # <8>\n",
    "\n",
    "            loss_train += loss.item()  # <9>\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))  # <10>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-21 20:21:20.284368 Epoch 1, Training loss 2.287555693970312\n",
      "2021-04-21 20:24:42.853466 Epoch 10, Training loss 1.3919866992079692\n",
      "2021-04-21 20:28:35.511324 Epoch 20, Training loss 1.2058600393097725\n",
      "2021-04-21 20:32:21.557189 Epoch 30, Training loss 1.1166145098788658\n",
      "2021-04-21 20:35:59.427709 Epoch 40, Training loss 1.0698939385773885\n",
      "2021-04-21 20:39:36.827536 Epoch 50, Training loss 1.0400219319574058\n",
      "2021-04-21 20:43:13.808751 Epoch 60, Training loss 1.0141821569951295\n",
      "2021-04-21 20:46:51.377711 Epoch 70, Training loss 0.9983639169836898\n",
      "2021-04-21 20:50:28.436299 Epoch 80, Training loss 0.9832006833513679\n",
      "2021-04-21 20:54:07.498179 Epoch 90, Training loss 0.9716682440179694\n",
      "2021-04-21 20:57:43.582146 Epoch 100, Training loss 0.9606901334832086\n",
      "2021-04-21 21:01:21.368229 Epoch 110, Training loss 0.9517096621758493\n",
      "2021-04-21 21:04:59.247559 Epoch 120, Training loss 0.9428336047150595\n",
      "2021-04-21 21:08:37.393238 Epoch 130, Training loss 0.93647877654761\n",
      "2021-04-21 21:12:15.113354 Epoch 140, Training loss 0.9271645683156865\n",
      "2021-04-21 21:15:53.935569 Epoch 150, Training loss 0.924394282081243\n",
      "2021-04-21 21:19:31.536647 Epoch 160, Training loss 0.9166067020057718\n",
      "2021-04-21 21:23:09.297930 Epoch 170, Training loss 0.91294764870268\n",
      "2021-04-21 21:26:48.119649 Epoch 180, Training loss 0.9088781151320319\n",
      "2021-04-21 21:30:26.841178 Epoch 190, Training loss 0.9055910966432917\n",
      "2021-04-21 21:34:05.350041 Epoch 200, Training loss 0.9008813470297152\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
    "                                           shuffle=True)  # <1>\n",
    "\n",
    "model = Net()  #  <2>\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)  #  <3>\n",
    "loss_fn = nn.CrossEntropyLoss()  #  <4>\n",
    "\n",
    "training_loop(  # <5>\n",
    "    n_epochs = 200,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.67\n",
      "Accuracy val: 0.64\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():  # <1>\n",
    "            for imgs, labels in loader:\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
    "                total += labels.shape[0]  # <3>\n",
    "                correct += int((predicted == labels).sum())  # <4>\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "        \n",
    "validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
