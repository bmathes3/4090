{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "basic-farming",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import time\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "forward-quarter",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "desperate-science",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\backup_pc/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Focus                     [3, 48, 3]                    \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  1     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  1    629760  models.common.C3                        [192, 192, 6]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  1   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  1   1476864  models.common.SPP                       [768, 768, [5, 9, 13]]        \n",
      "  9                -1  1   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1    343485  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
      "Model Summary: 391 layers, 21375645 parameters, 21375645 gradients, 51.4 GFLOPS\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding autoShape... \n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5m', pretrained=True)  # for file/URI/PIL/cv2/np inputs and NMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acknowledged-trauma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images\n",
    "for f in ['zidane.jpg', 'bus.jpg']:  # download 2 images\n",
    "    print(f'Downloading {f}...')\n",
    "    torch.hub.download_url_to_file('https://github.com/ultralytics/yolov5/releases/download/v1.0/' + f, f)\n",
    "img1 = Image.open('zidane.jpg')  # PIL image\n",
    "img2 = cv2.imread('bus.jpg')[:, :, ::-1]  # OpenCV image (BGR to RGB)\n",
    "imgs = [img1, img2]  # batched list of images\n",
    "#from PIL import Image\n",
    "#imgs = Image.open(\"C:/Users/backup_pc/yolov5/data/images/intersection.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "romantic-citizen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "results = model(imgs, size=640)  # includes NMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "funky-imagination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1: 395x675 12 persons, 1 bicycle, 8 cars, 1 truck, 7 traffic lights\n",
      "Saving results\\intersection.jpg, done.\n"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "results.print()  # print results to screen\n",
    "results.show()  # display results\n",
    "results.save()  # save as results1.jpg, results2.jpg... etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "controlled-simulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " tensor([[7.40971e+01, 3.18292e+02, 2.74968e+02, 3.77494e+02, 9.23869e-01, 2.00000e+00],\n",
      "        [6.21355e+02, 3.03209e+02, 6.54065e+02, 3.59416e+02, 8.28039e-01, 0.00000e+00],\n",
      "        [2.77735e+02, 3.06794e+02, 3.06350e+02, 3.56406e+02, 8.25762e-01, 0.00000e+00],\n",
      "        [2.44337e+01, 1.30279e+02, 4.55267e+01, 1.71181e+02, 7.76752e-01, 9.00000e+00],\n",
      "        [3.91932e+02, 3.09024e+02, 4.24386e+02, 3.31079e+02, 7.67970e-01, 2.00000e+00],\n",
      "        [2.77549e+01, 3.08917e+02, 4.61036e+01, 3.55797e+02, 7.12002e-01, 0.00000e+00],\n",
      "        [3.10602e+02, 3.07676e+02, 3.26235e+02, 3.55405e+02, 6.91051e-01, 0.00000e+00],\n",
      "        [8.60790e-01, 1.31235e+02, 1.91545e+01, 1.70599e+02, 6.78163e-01, 9.00000e+00],\n",
      "        [4.37581e+02, 3.05104e+02, 4.68818e+02, 3.57381e+02, 6.12053e-01, 0.00000e+00],\n",
      "        [4.97527e+02, 3.03069e+02, 5.20196e+02, 3.54113e+02, 6.07871e-01, 0.00000e+00],\n",
      "        [3.24182e+02, 3.06897e+02, 3.38895e+02, 3.53615e+02, 6.04528e-01, 0.00000e+00],\n",
      "        [6.57517e+02, 3.03024e+02, 6.75000e+02, 3.47322e+02, 6.00951e-01, 0.00000e+00],\n",
      "        [4.69356e+02, 2.00661e+02, 4.84913e+02, 2.25430e+02, 5.47497e-01, 9.00000e+00],\n",
      "        [2.63911e+02, 3.06194e+02, 2.83305e+02, 3.20692e+02, 5.27117e-01, 2.00000e+00],\n",
      "        [3.75040e+02, 3.11134e+02, 3.97324e+02, 3.53013e+02, 5.15910e-01, 0.00000e+00],\n",
      "        [1.25215e+02, 3.09129e+02, 1.37462e+02, 3.36561e+02, 5.12713e-01, 0.00000e+00],\n",
      "        [5.33147e+02, 3.24103e+02, 5.69005e+02, 3.50518e+02, 4.55190e-01, 1.00000e+00],\n",
      "        [4.80172e+02, 2.00981e+02, 4.91225e+02, 2.24633e+02, 4.43983e-01, 9.00000e+00],\n",
      "        [4.24901e+02, 3.03588e+02, 4.39204e+02, 3.46787e+02, 4.33648e-01, 0.00000e+00],\n",
      "        [4.62836e+02, 2.01567e+02, 4.77664e+02, 2.24935e+02, 4.29468e-01, 9.00000e+00],\n",
      "        [4.61781e+02, 3.12149e+02, 4.87218e+02, 3.46135e+02, 4.27349e-01, 2.00000e+00],\n",
      "        [5.36425e+02, 2.59389e+02, 5.41838e+02, 2.77801e+02, 3.77013e-01, 9.00000e+00],\n",
      "        [2.97997e+02, 3.05596e+02, 3.15205e+02, 3.18439e+02, 3.59751e-01, 2.00000e+00],\n",
      "        [2.64006e+02, 2.72605e+02, 2.70713e+02, 2.84566e+02, 3.54462e-01, 9.00000e+00],\n",
      "        [3.44372e+02, 3.06149e+02, 3.62182e+02, 3.47825e+02, 3.26165e-01, 0.00000e+00],\n",
      "        [5.14666e+02, 3.09744e+02, 5.47165e+02, 3.46107e+02, 2.87976e-01, 2.00000e+00],\n",
      "        [3.44684e+02, 3.01217e+02, 3.85628e+02, 3.43213e+02, 2.84426e-01, 2.00000e+00],\n",
      "        [3.46839e+02, 3.02474e+02, 3.84820e+02, 3.42350e+02, 2.69645e-01, 7.00000e+00],\n",
      "        [4.36981e+02, 3.06132e+02, 4.70727e+02, 3.54944e+02, 2.67563e-01, 2.00000e+00]])\n"
     ]
    }
   ],
   "source": [
    "print('\\n', results.xyxy[0])  # print img1 predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "operational-result",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "tough-saudi",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = stop - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "worldwide-puppy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 5.47234582901001\n"
     ]
    }
   ],
   "source": [
    "print('\\n', duration)  # print time it takes to run algorithm for images located in data/images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
